{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the S3 resource with the access key and secret from the datawarehouse's admin user\n",
    "s3 = boto3.resource('s3',\n",
    "                  aws_access_key_id='',\n",
    "                  aws_secret_access_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bucket =  s3.Bucket(\"udacity-dend\")\n",
    "\n",
    "# Iterate over bucket objects starting with \"log_data\" and print\n",
    "for obj in dataset_bucket.objects.filter(Prefix=\"log_data\"):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_json_file = dataset_bucket.Object('log_data/2018/11/2018-11-01-events.json')\n",
    "\n",
    "# Load and read the JSON file\n",
    "body = log_json_file.get()[\"Body\"]\n",
    "df = pd.read_json(body, lines=True)\n",
    "\n",
    "# Load and read the JSON file by turning the bytestream from the server into\n",
    "# an in-memory byte-stream using io.BytesIO (make sure you have sufficient memory to do this.)\n",
    "# import io\n",
    "# with io.BytesIO(log_json_file.get()['Body'].read()) as bio:\n",
    "#     df = pd.read_json(bio, lines=True)\n",
    "\n",
    "display(df[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over bucket objects starting with \"song_data\" and print\n",
    "for obj in dataset_bucket.objects.filter(Prefix=\"song_data\"):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_json_file = dataset_bucket.Object('song-data/J/V/L/TRJVLUK128F1483235.json')\n",
    "\n",
    "# Load and read the JSON file\n",
    "body = song_json_file.get()[\"Body\"]\n",
    "df = pd.read_json(body, lines=True)\n",
    "\n",
    "# Load and read the JSON file by turning the bytestream from the server into\n",
    "# an in-memory byte-stream using io.BytesIO (make sure you have sufficient memory to do this.)\n",
    "# import io\n",
    "# with io.BytesIO(song_json_file.get()['Body'].read()) as bio:\n",
    "#     df = pd.read_json(bio, lines=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_json_path_file = dataset_bucket.Object('log_json_path.json')\n",
    "\n",
    "# Load and read the JSON file\n",
    "body = log_json_path_file.get()[\"Body\"]\n",
    "df = pd.read_json(body)\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
